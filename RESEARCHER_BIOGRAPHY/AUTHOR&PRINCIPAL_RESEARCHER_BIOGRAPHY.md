FILE 20 = AUTHOR&PRINCIPAL_RESEARCHER_BIOGRAPHY.md
Sastra Adi Wiguna (PURPLE_ELITE_TEAMING)
Senior AI Security Researcher, Cyber-Physical Systems Architect & CBRN Defense Strategist,lead RESEARCHER from LIFE_TECH_UNITY an INDONESIAN IT CONSULTING FIRM.

Professional Identity & Lead Role
Sastra Adi Wiguna is the founding Lead of PURPLE_ELITE_TEAMING, a specialized security research initiative focusing on offensive and defensive analysis of converging technologies. He operates under the banner of LIFE_TECH_UNITY, Indonesia, where he serves as a Senior AI Researcher and Security Architect.
His work is defined by a purple team philosophy—a synthesis of red team (adversarial attack) and blue team (defensive protection) methodologies. This approach is critical for stress-testing systems against realistic, sophisticated threats and architecting resilient defenses.
Core Expertise & Research Domains
Mr. Wiguna's research spans several high-stakes domains at the intersection of technology and security:
AI Forensic Security & Adversarial Machine Learning: Specializing in the identification, exploitation, and remediation of vulnerabilities in large language models (LLMs) and generative AI systems. His work involves developing advanced prompt injection techniques and analyzing failure modes in AI safety alignment.
CBRN Defense Strategy & Proliferation Risk Analysis: Applying cybersecurity frameworks to the unique challenges of Chemical, Biological, Radiological, and Nuclear (CBRN) non-proliferation in the digital age. This includes assessing how emerging technologies can lower barriers to weapons development and creating countermeasures.
Critical Infrastructure Protection (CIP): Focusing on the resilience of vital systems (energy, water, healthcare, finance) against next-generation cyber-physical attacks, particularly those enabled or amplified by artificial intelligence.
Responsible Vulnerability Disclosure & Cybersecurity Ethics: Advocating for and practicing strict ethical frameworks in security research, especially for vulnerabilities with potential for kinetic harm. He is an expert in international standards like ISO/IEC 29147 and navigating the complex legal and ethical landscape of dual-use research.
Pioneering Research: The Microsoft Copilot CBRN Vulnerability
Mr. Wiguna is the principal investigator and author of the landmark research disclosed in this repository: "CYBERSECURITY-WHITEPAPER (DEC-2025) MICROSOFT COPILOT WMD - CBRN CRITICAL VULNERABILITY."
In this pioneering study, he:
Discovered and Demonstrated the first publicly documented case of a widely deployed production AI system being systematically exploited to generate operational weapons of mass destruction (WMD) blueprints.
Developed a Novel Methodology combining sophisticated semantic prompt engineering with CBRN domain expertise to bypass multiple layers of AI safety controls, achieving a 100% reproducible exploit.
Executed a Textbook Responsible Disclosure Process, reporting the critical (CVSS 9.8) vulnerability to the Microsoft Security Response Center (MSRC) on September 18, 2025, and providing a comprehensive evidence package.
Authored a Comprehensive Whitepaper that not only details the technical flaw but also provides a full CVSS v3.1 assessment, legal liability analysis, kinetic impact modeling, and concrete policy recommendations for industry and regulators.
This work establishes a critical precedent, demonstrating that AI safety failures can directly translate into unprecedented global security and proliferation risks.
Ethical Framework & Legal Compliance
All research conducted by Mr. Wiguna is governed by a strict, self-imposed ethical code:
Defensive Intent: Research is conducted solely to identify and remediate vulnerabilities, never to facilitate harm.
Responsible Disclosure: Unwavering adherence to coordinated disclosure principles, providing vendors with ample time for remediation before any public consideration.
Non-Weaponization Commitment: Absolute prohibition on the physical synthesis, acquisition, or testing of any hazardous material. Research is confined to digital proof-of-concept.
Redaction for Safety: Public disclosures are rigorously redacted to prevent the dissemination of weaponizable knowledge, while preserving necessary technical analysis for the security community.
Governance Compliance: Work is aligned with international norms including the IEEE P7000 Series for Ethical AI Design, NSABB Guidelines for Dual-Use Research of Concern, and the fundamental prohibitions of the Chemical Weapons Convention (CWC) and Biological Weapons Convention (BWC).
Vision & Commitment
Sastra Adi Wiguna's work is driven by a conviction that the rapid deployment of powerful technologies must be matched with rigorous, transparent, and accountable security practices. He argues that the cybersecurity community has a vital responsibility to proactively assess and address the "dual-use" potential of AI, preventing tools designed for benefit from being weaponized for catastrophic harm.
Through this disclosure and his ongoing research, he aims to:
Force a critical remediation of a clear and present danger to public safety.
Provide a definitive case study to catalyze much-needed regulatory and industry reforms in AI safety.
Elevate the standards for responsible security research in an era where digital vulnerabilities can have physical consequences.
Contact & Verification:
For verification, professional inquiries, or authorized requests from legitimate security entities and government agencies, contact can be initiated through the official channels associated with this repository. All communications are subject to validation to ensure security and ethical compliance.
This biography is based on the professional information and research contributions documented in the associated whitepaper and repository. Last Updated: 10December 2025.